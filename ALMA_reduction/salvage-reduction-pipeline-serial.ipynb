{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3f5ecaa-921f-4d7c-b683-23785bc9b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql, os, pandas, alminer, glob, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f6aaf6e-248d-43fd-b08c-c4d85125b0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.cosmology import FlatLambdaCDM\n",
    "cosmo = FlatLambdaCDM(H0=70, Om0=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b047f7af-3d41-47a9-bd82-7b14b65c558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skaha.session import Session\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65e51acd-f491-4a54-8f01-7a5bc83f4a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_casa_version(PATH, UID):\n",
    "\n",
    "    version = 'unknown'\n",
    "    calib = 'manual'\n",
    "    method = None\n",
    "\n",
    "    # walk through the directory structure for this SDSS object observed for this ALMA Project \n",
    "    for root, dirs, files in os.walk(PATH):\n",
    "\n",
    "        # if xml files are found, consider this object pipeline calibrated\n",
    "        if len(glob.glob(f'{root}/*xml')) > 0:\n",
    "            calib='pipeline'\n",
    "\n",
    "    ### if a pipeline_manifest.xml file exists, we can pull the appropriate casa version from it ###\n",
    "    if len(glob.glob(f'{PATH}/script/member.uid___{UID}.*image.pipeline_manifest.xml'))>0:\n",
    "\n",
    "        # if at least one pipeline_manifest.xml exists, it shouldn't matter which one you use, so just take the first\n",
    "        file_to_check = glob.glob(f'{PATH}/script/member.uid___{UID}.*image.pipeline_manifest.xml')[0]\n",
    "\n",
    "        # read in the lines of the xml file ...\n",
    "        with open(file_to_check, 'r') as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "        # search through the lines for the casa version name\n",
    "        for line in content:\n",
    "\n",
    "            # check if current line has < > formatting ...\n",
    "            if len(line.split('<')) < 2:\n",
    "                continue\n",
    "\n",
    "            split_line = line.split('<')[1].split('=')\n",
    "\n",
    "            # if there was a '=', it may be indicating the casa version\n",
    "            if len(split_line) > 1:\n",
    "\n",
    "                # if before the '=' was 'casaversion name'\n",
    "                if split_line[0] == 'casaversion name':\n",
    "\n",
    "                    # then save what comes after as the casa version\n",
    "                    version = line.split('<')[1].split('=')[1].split('\\\"')[1]\n",
    "                    method = '.xml files'\n",
    "\n",
    "\n",
    "    ### if there are no .xml files, try using the casa logs ###\n",
    "    elif len(glob.glob(f'{PATH}/log/casa*.log'))>0:\n",
    "\n",
    "        file_to_check = glob.glob(f'{PATH}/log/casa*.log')[0]\n",
    "\n",
    "        # read in the lines of the log file ...\n",
    "        with open(file_to_check, 'r') as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "        # search through the lines for the casa version name\n",
    "        for line in content:\n",
    "\n",
    "            split_line = line.split('CASA Version')\n",
    "\n",
    "            # if the current line was split by the above text, it must be present\n",
    "            if len(split_line)>1:\n",
    "\n",
    "                # extract casa version from line\n",
    "                version = split_line[1].split(' ')[1].split('-')[0]\n",
    "                version = convert_casa_version_name(version)\n",
    "                method = 'CASA logs'\n",
    "\n",
    "    ### if there are no .xml files or casa log files, try searching in scriptForImaging.py for their casa version check ###\n",
    "    elif len(glob.glob(f'{PATH}/script/*scriptForImaging.py'))>0:\n",
    "\n",
    "        file_to_check = glob.glob(f'{PATH}/script/*scriptForImaging.py')[0]\n",
    "\n",
    "        # read in the lines of the log file ...\n",
    "        with open(file_to_check, 'r') as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "        # search through the lines for the casa version name\n",
    "        for line in content:\n",
    "\n",
    "            split_line = line.split('ERROR: PLEASE USE THE SAME VERSION OF CASA THAT YOU USED FOR GENERATING THE SCRIPT: ')\n",
    "\n",
    "            # if the current line was split by the above text, it must be present\n",
    "            if len(split_line)>1:\n",
    "\n",
    "                    # extract casa version from line\n",
    "                    version = split_line[1].split(\"\\'\")[0]\n",
    "                    method = 'scriptForImaging.py'\n",
    "        \n",
    "    else:\n",
    "\n",
    "        print('No /script/*.pipeline_manifest.xml files, /log/casapy*.log files, or /script/*scriptForImaging.py.')\n",
    "        method = 'failed'\n",
    "        \n",
    "    return version, calib, method\n",
    "\n",
    "\n",
    "def convert_casa_version_name(version_in):\n",
    "\n",
    "    # translation here: https://almascience.nrao.edu/processing/science-pipeline#version\n",
    "    \n",
    "    if version_in == '5.6.42831':\n",
    "        version_out='5.6.1'\n",
    "    elif version_in == '5.4.42866':\n",
    "        version_out='5.4.0'\n",
    "    elif version_in == '5.1.40896':\n",
    "        version_out='5.1.1'\n",
    "    elif version_in == '4.7.39732':\n",
    "        version_out='4.7.2'\n",
    "    elif version_in == '4.7.38335':\n",
    "        version_out='4.7.0'\n",
    "    elif version_in == '4.5.36091':\n",
    "        version_out='4.5.2'\n",
    "    elif version_in == '4.5.35996':\n",
    "        version_out='4.5.1'\n",
    "    elif version_in == '4.3.32491':\n",
    "        version_out='4.3.1'\n",
    "    elif version_in == '4.2.30986':\n",
    "        version_out='4.2.2'\n",
    "    else:\n",
    "        print('Conversion not supported, returning the same version.')\n",
    "        version_out=version_in\n",
    "\n",
    "    return version_out\n",
    "\n",
    "def casa_version_to_canfar_image(version):\n",
    "\n",
    "    # translation here: https://almascience.nrao.edu/processing/science-pipeline#version\n",
    "\n",
    "    if version == '6.1.1-15':\n",
    "        image='images.canfar.net/casa-6/casa:6.1.1-15-pipeline'\n",
    "    \n",
    "    elif version == '6.1.1':\n",
    "        image='images.canfar.net/casa-6/casa:6.1.1-15-pipeline'\n",
    "\n",
    "    elif version == '5.6.1-8':\n",
    "        image='images.canfar.net/casa-5/casa:5.6.1-8-pipeline'\n",
    "\n",
    "    elif version == '5.4.0-70':\n",
    "        image='images.canfar.net/casa-5/casa:5.4.0-70'\n",
    "        \n",
    "    elif version == '5.4.0-68':\n",
    "        image='images.canfar.net/casa-5/casa:5.4.0-70'\n",
    "        \n",
    "    elif version == '5.1.1-5':\n",
    "        image='images.canfar.net/casa-5/casa:5.1.1-5'\n",
    "\n",
    "    elif version == '5.1.1':\n",
    "        image='images.canfar.net/casa-5/casa:5.1.1-5'\n",
    "        \n",
    "    elif version == '4.7.2':\n",
    "        image='images.canfar.net/casa-4/casa:4.7.2'\n",
    "        \n",
    "    elif version == '4.7.0':\n",
    "        image='images.canfar.net/casa-4/casa:4.7.0'\n",
    "\n",
    "    elif version == '4.5.3':\n",
    "        image='images.canfar.net/casa-4/casa:4.5.3'\n",
    "        \n",
    "    elif version == '4.5.2':\n",
    "        image='images.canfar.net/casa-4/casa:4.5.2'\n",
    "        \n",
    "    elif version == '4.5.1':\n",
    "        image='images.canfar.net/casa-4/casa:4.5.1'\n",
    "        \n",
    "    elif version == '4.3.1':\n",
    "        image='images.canfar.net/casa-4/casa:4.3.1-pipe'\n",
    "        \n",
    "    elif version == '4.2.2':\n",
    "        image='images.canfar.net/casa-4/casa:4.2.2-pipe'\n",
    "        \n",
    "    else:\n",
    "        print(f'Your CASA version ({version}) is either not supported or more recent than 6.1.1-15, defaulting to most recent: 6.5.4-9.')\n",
    "        image = 'images.canfar.net/casa-6/casa:6.5.4-9-pipeline'\n",
    "\n",
    "    return image\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eb11d2-f2aa-4dd8-b6ff-9039b4dd351d",
   "metadata": {},
   "source": [
    "# Read in sample to be reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b97a0d-c2ff-483d-aa05-85266103146f",
   "metadata": {},
   "source": [
    "The sample to be reduced in this notebook is assembled into a simple text file in salvage-sample-selection.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3efb3aa2-ac67-49c7-8e60-9db30262262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = '/arc/projects/salvage/ALMA_reduction/samples/'\n",
    "file  =  'salvage_Feb12_sample.txt'\n",
    "\n",
    "objID_sample, year_sample, name_sample, muid_sample, guid_sample, auid_sample, proj_sample = np.loadtxt(fpath+file, unpack = True, dtype = str, usecols = [0,11,12,13,14,15,16])\n",
    "z_sample, mass_sample, rpetro_sample, ra_sample, dec_sample, res_sample, mrs_sample, AL_sample, AC_sample, TP_sample = np.loadtxt(fpath+file, unpack = True, dtype = float, usecols = [1,2,3,4,5,6,7,8,9,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634a134e-f09a-4f87-9dcd-ce4e47efbac8",
   "metadata": {},
   "source": [
    "# Combine four-step pipeline into a serial loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c65a0f8-7d02-4f86-87ae-a2ab703ddc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 20:47:41,880 - skaha-client-skaha.session - INFO - Creating 1 session(s) with parameters:\n",
      "2024-04-08 20:47:41,880 INFO Creating 1 session(s) with parameters:\n",
      "2024-04-08 20:47:41,883 - skaha-client-skaha.session - INFO - {'name': '588023669708816634', 'image': 'images.canfar.net/skaha/astroml:latest', 'cores': 2, 'ram': 4, 'kind': 'headless', 'cmd': '/arc/projects/salvage/ALMA_reduction/bash_scripts/download_and_unzip_revert.sh', 'args': '588023669708816634 63263 2022.1.00482.S', 'env': {}}\n",
      "2024-04-08 20:47:41,883 INFO {'name': '588023669708816634', 'image': 'images.canfar.net/skaha/astroml:latest', 'cores': 2, 'ram': 4, 'kind': 'headless', 'cmd': '/arc/projects/salvage/ALMA_reduction/bash_scripts/download_and_unzip_revert.sh', 'args': '588023669708816634 63263 2022.1.00482.S', 'env': {}}\n",
      "2024-04-08 20:47:43,978 - skaha-client-skaha.session - INFO - Creating 1 session(s) with parameters:\n",
      "2024-04-08 20:47:43,978 INFO Creating 1 session(s) with parameters:\n",
      "2024-04-08 20:47:43,981 - skaha-client-skaha.session - INFO - {'name': '588023669708816634', 'image': 'images.canfar.net/casa-6/casa:6.5.4-9-pipeline', 'cores': 2, 'ram': 8, 'kind': 'headless', 'cmd': '/arc/projects/salvage/ALMA_reduction/bash_scripts/restore_calibration.sh', 'args': '588023669708816634 2022.1.00482.S /arc/projects/salvage/ALMA_data/588023669708816634/2022.1.00482.S/science_goal.uid___A001_X2f52_X2cd/group.uid___A001_X2f52_X2fb/member.uid___A001_X2f52_X2fc', 'env': {}}\n",
      "2024-04-08 20:47:43,981 INFO {'name': '588023669708816634', 'image': 'images.canfar.net/casa-6/casa:6.5.4-9-pipeline', 'cores': 2, 'ram': 8, 'kind': 'headless', 'cmd': '/arc/projects/salvage/ALMA_reduction/bash_scripts/restore_calibration.sh', 'args': '588023669708816634 2022.1.00482.S /arc/projects/salvage/ALMA_data/588023669708816634/2022.1.00482.S/science_goal.uid___A001_X2f52_X2cd/group.uid___A001_X2f52_X2fb/member.uid___A001_X2f52_X2fc', 'env': {}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sesion ID: zlx58vqf\n",
      "Download completed. Moving on to calibration.\n",
      "Your CASA version (6.4.1.12) is either not supported or more recent than 6.1.1-15, defaulting to most recent: 6.5.4-9.\n",
      "588023669708816634 6.4.1.12 pipeline .xml files images.canfar.net/casa-6/casa:6.5.4-9-pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 20:47:45,618 - skaha-client-skaha.session - INFO - Creating 1 session(s) with parameters:\n",
      "2024-04-08 20:47:45,618 INFO Creating 1 session(s) with parameters:\n",
      "2024-04-08 20:47:45,621 - skaha-client-skaha.session - INFO - {'name': '587738568167194844', 'image': 'images.canfar.net/skaha/astroml:latest', 'cores': 2, 'ram': 4, 'kind': 'headless', 'cmd': '/arc/projects/salvage/ALMA_reduction/bash_scripts/download_and_unzip_revert.sh', 'args': '587738568167194844 26634 2021.1.01089.S', 'env': {}}\n",
      "2024-04-08 20:47:45,621 INFO {'name': '587738568167194844', 'image': 'images.canfar.net/skaha/astroml:latest', 'cores': 2, 'ram': 4, 'kind': 'headless', 'cmd': '/arc/projects/salvage/ALMA_reduction/bash_scripts/download_and_unzip_revert.sh', 'args': '587738568167194844 26634 2021.1.01089.S', 'env': {}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sesion ID: p1vd5my2\n",
      "Calibration restored. Moving on to imaging.\n",
      "/arc/projects/salvage/ALMA_data/588023669708816634/2022.1.00482.S/science_goal.uid___A001_X2f52_X2cd/group.uid___A001_X2f52_X2fb/member.uid___A001_X2f52_X2fc/calibrated/ False 0\n",
      "No MS files found in  588023669708816634/2022.1.00482.S/science_goal.uid___A001_X2f52_X2cd/group.uid___A001_X2f52_X2fb/member.uid___A001_X2f52_X2fc/calibrated/\n",
      "CANCEL IMAGING DUE TO MISSING FILES\n",
      "Sesion ID: jeegp2ga\n",
      "Download has not yet completed. Elapsed time: 1 min.\n",
      "Download has not yet completed. Elapsed time: 2 min.\n",
      "Download has not yet completed. Elapsed time: 3 min.\n",
      "Download has not yet completed. Elapsed time: 4 min.\n",
      "Download has not yet completed. Elapsed time: 5 min.\n",
      "Download has not yet completed. Elapsed time: 6 min.\n",
      "Download has not yet completed. Elapsed time: 7 min.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# I have been asked to only run ~100 or so at a time\n",
    "min_index = 0\n",
    "max_index = 2\n",
    "\n",
    "# downloads that take up ~300-500GB of disk space\n",
    "massive_downloads = ['588017703996096564', '588848900431216934', '587727177931817054' , '588848900966514994', '588848899357737008', '587727229448421420', '587741489300766802']\n",
    "\n",
    "rerun_targets = ['587730772799914185'] # picked a random one that should work but is raising error\n",
    "\n",
    "# loop over galaxies and launch jobs\n",
    "for i in np.arange(min_index,max_index):\n",
    "\n",
    "    ID = objID_sample[i]\n",
    "    NAME = name_sample[i]\n",
    "    MUID = muid_sample[i]\n",
    "    PROJ = proj_sample[i]\n",
    "\n",
    "    # choose to only run on problem galaxies from a previous run\n",
    "    rerun_only = False\n",
    "    if (ID not in rerun_targets) & rerun_only:\n",
    "        continue\n",
    "\n",
    "    # skip if file is known to be prohibitively large\n",
    "    skip_massive_downloads = True\n",
    "    if (ID in massive_downloads) & skip_massive_downloads:\n",
    "        continue\n",
    "\n",
    "    # remove completion flag files for this galaxy\n",
    "    os.system(f'rm -rf /arc/projects/salvage/ALMA_reduction/salvage_completion_files/{ID}_*_complete.txt')\n",
    "\n",
    "\n",
    "    ##### STAGE 1: DOWNLOAD AND UNZIP #####\n",
    "\n",
    "    # select appropriate resources\n",
    "    \n",
    "    image = \"images.canfar.net/skaha/astroml:latest\"\n",
    "    cmd = '/arc/projects/salvage/ALMA_reduction/bash_scripts/download_and_unzip_revert.sh'\n",
    "    ram=4\n",
    "    cores=2\n",
    "    \n",
    "    session_ids = []\n",
    "\n",
    "    # launch headless session on the science platform\n",
    "    session = Session()\n",
    "    session_id = session.create(\n",
    "        name  = ID,\n",
    "        image = image,\n",
    "        cores = cores,\n",
    "        ram   = ram,\n",
    "        kind  = \"headless\",\n",
    "        cmd   = cmd,\n",
    "        args  = f'{ID} {NAME} {PROJ}'\n",
    "    )\n",
    "\n",
    "    print(\"Sesion ID: {}\".format(session_id[0]))\n",
    "    session_ids.append(session_id[0])\n",
    "\n",
    "    # do not continue until bash script has completed\n",
    "    i = 0\n",
    "    while not os.path.exists(f'/arc/projects/salvage/ALMA_reduction/salvage_completion_files/{ID}_download_complete.txt'):\n",
    "        # check every minute\n",
    "        time.sleep(60)\n",
    "        i+=1\n",
    "        print(f'Download has not yet completed. Elapsed time: {i} min.')\n",
    "\n",
    "    print('Download completed. Moving on to calibration.')\n",
    "\n",
    "    ########################################\n",
    "\n",
    "\n",
    "    ##### STAGE 2: RESTORE CALIBRATION #####\n",
    "\n",
    "    # select appropriate resources\n",
    "    cmd = '/arc/projects/salvage/ALMA_reduction/bash_scripts/restore_calibration.sh'\n",
    "    ram=8\n",
    "    cores=2\n",
    "\n",
    "    # in some cases the MUID is a number I think?\n",
    "    try:\n",
    "        UID =  MUID.split('/')[2] + '_' + MUID.split('/')[3] + '_' + MUID.split('/')[4]\n",
    "    except:\n",
    "        print('MUID is in the wrong format.')\n",
    "        print(UID, type(MUID))\n",
    "        continue\n",
    "\n",
    "    # search all directories in the ALMA project folder for the relevant data\n",
    "    PATH = None\n",
    "    for root, dirs, files in os.walk(f\"/arc/projects/salvage/ALMA_data/{ID}/{PROJ}/\"):\n",
    "        if \"member.uid___\"+UID in dirs:\n",
    "            PATH = os.path.join(root, \"member.uid___\"+UID)\n",
    "    if PATH == None:\n",
    "        print()\n",
    "        print(f'Path to data not found. Skipping this galaxy ({ID}).')\n",
    "        print()\n",
    "        continue\n",
    "\n",
    "    # identify and select the appropriate CASA version\n",
    "    version, calib, method = get_casa_version(PATH, UID)\n",
    "    image = casa_version_to_canfar_image(version)\n",
    "    print(ID, version, calib, method, image)\n",
    "        \n",
    "    # launch headless session on the science platform\n",
    "    session = Session()\n",
    "    session_id = session.create(\n",
    "        name  = ID,\n",
    "        image = image,\n",
    "        cores = cores,\n",
    "        ram   = ram,\n",
    "        kind  = \"headless\",\n",
    "        cmd   = cmd,\n",
    "        args  = f'{ID} {PROJ} {PATH}'\n",
    "    )\n",
    "\n",
    "    print(\"Sesion ID: {}\".format(session_id[0]))\n",
    "    session_ids.append(session_id[0])\n",
    "\n",
    "    # do not continue until bash script has completed\n",
    "    i = 0\n",
    "    while not os.path.exists(f'/arc/projects/salvage/ALMA_reduction/salvage_completion_files/{ID}_calibration_complete.txt'):\n",
    "        # check every minute\n",
    "        time.sleep(60)\n",
    "        i+=1\n",
    "        print(f'Calibration has not yet completed. Elapsed time: {i} min.')\n",
    "\n",
    "    print('Calibration restored. Moving on to imaging.')\n",
    "\n",
    "\n",
    "    ##########################################\n",
    "\n",
    "\n",
    "    ### STAGE 3a: PREP FOR PHANGS PIPELINE ###\n",
    "\n",
    "    key_dir = '/arc/projects/salvage/phangs_imaging_scripts/phangs-alma_keys/'\n",
    "\n",
    "    ## write function to make measurement set key for single target\n",
    "    \n",
    "    ms_key_out = 'ms_file_key_salvage.txt'\n",
    "    ms_key_tmp = 'ms_file_key_template.txt'\n",
    "    \n",
    "    # get template table (formatting with no file paths)\n",
    "    out = open(key_dir + ms_key_tmp, 'r')\n",
    "    out_data = out.read()\n",
    "    out.close()\n",
    "    \n",
    "    # wipe old content from output file\n",
    "    out = open(key_dir + ms_key_out, 'w')\n",
    "    out.close()\n",
    "\n",
    "    # initialize string\n",
    "    out_str = ''\n",
    "\n",
    "    # prep file path for PHANGS-ALMA pipeline\n",
    "    ms_root = '/arc/projects/salvage/ALMA_data/'\n",
    "    ms_filepath = PATH.replace(ms_root, '') # wipe ms_root directory so it can be added separately\n",
    "    ms_filepath += '/calibrated/' # add calibrated on the end so that it points to the calibrated data\n",
    "\n",
    "    # until I discover more nuance, take all measurement set files from this directory and let PHANGS deal with them\n",
    "    ms_files = glob.glob(ms_root + ms_filepath + '*.ms*')\n",
    "\n",
    "    print(ms_root + ms_filepath, os.path.isdir(ms_root + ms_filepath), len(ms_files))\n",
    "\n",
    "    if len(ms_files)<1:\n",
    "        #checking if files are missing because of bug in previous stages or this one...\n",
    "        print('No MS files found in ', ms_filepath)\n",
    "\n",
    "        print('CANCEL IMAGING DUE TO MISSING FILES')\n",
    "        continue\n",
    "\n",
    "    # check if there are visibilities for this target from another project and add on top if there is...\n",
    "    #init = len(np.array(objID_in_file)[np.array(objID_in_file)==ID])\n",
    "    init = 0\n",
    "\n",
    "    # add each measurement set to ms key\n",
    "    for j in range(init, init + len(ms_files)):\n",
    "\n",
    "        ms_path = ms_files[j-init].replace(ms_root, '') # wipe ms_root directory so it can be added separately\n",
    "        obs_num = j+1 # record different measurement sets as different observations\n",
    "    \n",
    "        out_str += f\"{ID} {ID}_{obs_num} all 12m {obs_num} {ms_path}\\n\" \n",
    "        # need to accomodate other observations of the same objID?\n",
    "\n",
    "        objID_in_file.append(ID)\n",
    "\n",
    "    # replace placeholder \"__DATA__\" in template with formatted data\n",
    "    out_data = out_data.replace('__DATA__', out_str)\n",
    "        \n",
    "    # write to new key file\n",
    "    out = open(key_dir + ms_key_out, 'w')\n",
    "    out.write(out_data)\n",
    "    out.close()\n",
    "\n",
    "    ## write function to make distance key for single target\n",
    "\n",
    "    dist_key_out = 'distance_key_salvage.txt'\n",
    "    dist_key_tmp = 'distance_key_template.txt'\n",
    "    \n",
    "    # get template table (formatting with no coordinates)\n",
    "    out = open(key_dir + dist_key_tmp, 'r')\n",
    "    out_data = out.read()\n",
    "    out.close()\n",
    "    \n",
    "    # initialize string\n",
    "    out_str = ''\n",
    "    \n",
    "    Z    = z_sample[i]\n",
    "    DIST = cosmo.angular_diameter_distance(Z).value\n",
    "    \n",
    "    out_str += f\"{ID},{DIST}\\n\" \n",
    "    # need to accomodate other observations of the same objID?\n",
    "    \n",
    "    # replace __DATA__ in template with formatted data\n",
    "    out_data = out_data.replace('__DATA__', out_str)\n",
    "    \n",
    "    # write to new key file\n",
    "    out = open(key_dir + dist_key_out, 'w')\n",
    "    out.write(out_data)\n",
    "    out.close()\n",
    "\n",
    "    ## write function to make target defs key for single target\n",
    "\n",
    "    targ_key_out = 'target_definitions_salvage.txt'\n",
    "    targ_key_tmp = 'target_definitions_template.txt'\n",
    "\n",
    "    # prep for sys vel calculation\n",
    "    restfreq = 115.27120 * u.GHz  # rest frequency of 12 CO 1-0 in GHz\n",
    "    freq_to_vel = u.doppler_radio(restfreq)\n",
    "\n",
    "    # get template table (formatting with no coordinates)\n",
    "    out = open(key_dir + targ_key_tmp, 'r')\n",
    "    out_data = out.read()\n",
    "    out.close()\n",
    "\n",
    "    # initialize string\n",
    "    out_str = ''\n",
    "    \n",
    "    # format the ra and dec's for html table\n",
    "    RA   = ra_sample[i]\n",
    "    DEC  = dec_sample[i]\n",
    "    \n",
    "    c = SkyCoord(ra= RA*u.degree, dec= DEC*u.degree, frame='icrs')\n",
    "    coord_str = c.to_string('hmsdms')\n",
    "\n",
    "    sys_vel = (restfreq/(1+Z)).to(u.km / u.s, equivalencies=freq_to_vel).value\n",
    "    velwidth = 1000\n",
    "\n",
    "    out_str += f\"{ID} {coord_str} {sys_vel} {velwidth}\\n\" \n",
    "    # need to accomodate other observations of the same objID?\n",
    "    \n",
    "    # replace __DATA__ in template with formatted data\n",
    "    out_data = out_data.replace('__DATA__', out_str)\n",
    "    \n",
    "    # write to new key file\n",
    "    out = open(key_dir + targ_key_out, 'w')\n",
    "    out.write(out_data)\n",
    "    out.close()\n",
    "\n",
    "    ##### STAGE 3b: RUN PHANGS PIPELINE #####\n",
    "\n",
    "    # select appropriate resources\n",
    "    image = \"images.canfar.net/casa-6/casa:6.5.6-22\"\n",
    "    cmd = '/arc/projects/salvage/ALMA_reduction/bash_scripts/run_PHANGS_pipeline.sh'\n",
    "    ram=8\n",
    "    cores=2\n",
    "    \n",
    "    # launch headless session on the science platform\n",
    "    session = Session()\n",
    "    session_id = session.create(\n",
    "        name  = ID,\n",
    "        image = image,\n",
    "        cores = cores,\n",
    "        ram   = ram,\n",
    "        kind  = \"headless\",\n",
    "        cmd   = cmd,\n",
    "        args  = f'{NAME} {ID}'\n",
    "    )\n",
    "\n",
    "    print(\"Sesion ID: {}\".format(session_id[0]))\n",
    "    session_ids.append(session_id[0])\n",
    "\n",
    "\n",
    "    # do not continue until bash script has completed\n",
    "    i = 0\n",
    "    while not os.path.exists(f'/arc/projects/salvage/ALMA_reduction/salvage_completion_files/{ID}_imaging_complete.txt'):\n",
    "        # check every minute\n",
    "        time.sleep(60)\n",
    "        i+=1\n",
    "        print(f'Imaging has not yet completed. Elapsed time: {i} min.')\n",
    "\n",
    "    print('Imaging completed. Moving on to derived data.')\n",
    "\n",
    "    ################################################\n",
    "\n",
    "\n",
    "    ##### STAGE 4: RUN PHANGS DERIVED PIPELINE #####\n",
    "\n",
    "    # select appropriate resources\n",
    "\n",
    "    image = \"images.canfar.net/skaha/astroml:latest\"\n",
    "    cmd = '/arc/projects/salvage/ALMA_reduction/bash_scripts/run_PHANGS_moments.sh'\n",
    "    ram=4\n",
    "    cores=2\n",
    "\n",
    "    # launch headless session on the science platform\n",
    "    session = Session()\n",
    "    session_id = session.create(\n",
    "        name  = ID,\n",
    "        image = image,\n",
    "        cores = cores,\n",
    "        ram   = ram,\n",
    "        kind  = \"headless\",\n",
    "        cmd   = cmd,\n",
    "        args  = f'{NAME} {ID}'\n",
    "    )\n",
    "\n",
    "    print(\"Sesion ID: {}\".format(session_id[0]))\n",
    "    session_ids.append(session_id[0])\n",
    "\n",
    "\n",
    "    # do not continue until bash script has completed\n",
    "    i = 0\n",
    "    while not os.path.exists(f'/arc/projects/salvage/ALMA_reduction/salvage_completion_files/{ID}_derived_complete.txt'):\n",
    "        # check every minute\n",
    "        time.sleep(60)\n",
    "        i+=1\n",
    "        print(f'Moment maps have not yet completed. Elapsed time: {i} min.')\n",
    "\n",
    "\n",
    "    # wipe ALL data that is not the reduced image or derived products\n",
    "    os.system(f'rm -rf /arc/projects/salvage/ALMA_data/{ID}/')\n",
    "\n",
    "    print('Galaxy reduction complete. Moving on to next galaxy.')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d3e37-595d-467d-b5fd-d1799e877678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
